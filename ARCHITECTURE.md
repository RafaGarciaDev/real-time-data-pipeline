# ğŸ—ï¸ Arquitetura do Sistema

## VisÃ£o Geral

Este documento descreve a arquitetura tÃ©cnica do Pipeline de Dados em Tempo Real, detalhando cada componente, suas responsabilidades e como eles interagem.

## Componentes Principais

### 1. Apache Kafka

**Responsabilidade**: Message Broker e Log de Eventos

**Tecnologia**: 
- Kafka 3.5.0
- Zookeeper para coordenaÃ§Ã£o

**ConfiguraÃ§Ãµes**:
- 1 broker
- ReplicaÃ§Ã£o: 1 (single node)
- PartiÃ§Ãµes: ConfigurÃ¡vel por tÃ³pico
- Retention: 7 dias

**Fluxo de Dados**:
```
Producer â†’ Kafka Topic â†’ Consumer(s)
```

### 2. Data Producer

**Responsabilidade**: Gerar eventos simulados de e-commerce

**Tecnologia**: 
- Python 3.9
- kafka-python
- Faker para dados sintÃ©ticos

**Tipos de Eventos Gerados**:
1. `page_view` - VisualizaÃ§Ã£o de pÃ¡gina
2. `add_to_cart` - AdiÃ§Ã£o ao carrinho
3. `remove_from_cart` - RemoÃ§Ã£o do carrinho
4. `purchase` - Compra realizada
5. `search` - Busca de produtos

**ConfiguraÃ§Ãµes**:
- Taxa padrÃ£o: 2 eventos/segundo
- SessÃµes de usuÃ¡rio: Mantidas em memÃ³ria
- Retry logic: 5 tentativas com backoff exponencial

**Estrutura de Evento**:
```json
{
  "event_id": "uuid",
  "event_type": "purchase",
  "timestamp": "2024-01-01T00:00:00",
  "user_id": "USER001",
  "session_id": "uuid",
  "product": {
    "id": "PROD001",
    "name": "Product Name",
    "category": "Electronics",
    "price": 999.99
  },
  "quantity": 1,
  "total_amount": 999.99,
  "payment_method": "credit_card"
}
```

### 3. Data Consumer

**Responsabilidade**: Processar eventos e persistir em banco de dados

**Tecnologia**:
- Python 3.9
- kafka-python
- psycopg2 (PostgreSQL driver)

**Processamento**:
1. Consome mensagens do Kafka
2. Valida estrutura do evento
3. Extrai e normaliza dados
4. Persiste em PostgreSQL
5. Commit de offset

**OtimizaÃ§Ãµes**:
- Batch processing (100 eventos por lote)
- Connection pooling (atÃ© 10 conexÃµes)
- Auto-commit de offsets
- Timeout configurÃ¡vel

### 4. PostgreSQL

**Responsabilidade**: Armazenamento persistente de dados

**Tecnologia**: PostgreSQL 15

**Schema**:

```sql
events
â”œâ”€â”€ id (SERIAL)
â”œâ”€â”€ event_id (VARCHAR, UNIQUE)
â”œâ”€â”€ event_type (VARCHAR)
â”œâ”€â”€ timestamp (TIMESTAMP)
â”œâ”€â”€ user_id (VARCHAR)
â””â”€â”€ session_id (VARCHAR)

products
â”œâ”€â”€ id (SERIAL)
â”œâ”€â”€ product_id (VARCHAR, UNIQUE)
â”œâ”€â”€ product_name (VARCHAR)
â”œâ”€â”€ category (VARCHAR)
â””â”€â”€ price (DECIMAL)

transactions
â”œâ”€â”€ id (SERIAL)
â”œâ”€â”€ transaction_id (VARCHAR, UNIQUE)
â”œâ”€â”€ event_id (FK â†’ events)
â”œâ”€â”€ product_id (FK â†’ products)
â”œâ”€â”€ quantity (INTEGER)
â”œâ”€â”€ total_amount (DECIMAL)
â”œâ”€â”€ payment_method (VARCHAR)
â””â”€â”€ timestamp (TIMESTAMP)
```

**Ãndices**:
- `idx_events_timestamp` - Queries temporais
- `idx_events_user_id` - AnÃ¡lise por usuÃ¡rio
- `idx_transactions_product_id` - AnÃ¡lise de produtos
- `idx_products_category` - AgregaÃ§Ãµes por categoria

**Views Materializadas**:
- `sales_by_category` - Vendas agregadas por categoria
- `top_products` - Produtos mais vendidos
- `daily_metrics` - MÃ©tricas diÃ¡rias

### 5. Dashboard Web

**Responsabilidade**: VisualizaÃ§Ã£o em tempo real

**Tecnologia**:
- Flask (Python web framework)
- Plotly.js para grÃ¡ficos
- HTML/CSS/JavaScript

**APIs REST**:

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/` | GET | PÃ¡gina principal do dashboard |
| `/health` | GET | Health check |
| `/api/metrics/summary` | GET | MÃ©tricas resumidas |
| `/api/metrics/timeline` | GET | SÃ©rie temporal de eventos |
| `/api/metrics/top-products` | GET | Top 10 produtos |
| `/api/metrics/by-category` | GET | MÃ©tricas por categoria |
| `/api/metrics/event-types` | GET | DistribuiÃ§Ã£o de tipos |
| `/api/metrics/realtime` | GET | MÃ©tricas do Ãºltimo minuto |

**AtualizaÃ§Ã£o**:
- Polling a cada 5 segundos
- GrÃ¡ficos interativos com Plotly
- Responsivo (mobile-friendly)

## Fluxo de Dados Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer  â”‚ Gera eventos a 2/s
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ Kafka Protocol
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka    â”‚ Armazena em tÃ³pico
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ Consumer Group
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Consumer  â”‚ Processa em lotes
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ SQL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL â”‚ Persiste dados
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard  â”‚ Visualiza mÃ©tricas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PadrÃµes de Design Utilizados

### 1. Producer-Consumer Pattern
Kafka implementa naturalmente este padrÃ£o, permitindo desacoplamento entre produtores e consumidores.

### 2. Connection Pool Pattern
Consumer usa pool de conexÃµes PostgreSQL para melhor performance.

### 3. Batch Processing Pattern
Eventos sÃ£o processados em lotes para reduzir I/O.

### 4. Retry Pattern
Producer implementa retry com backoff exponencial.

### 5. Health Check Pattern
Todos os serviÃ§os expÃµem endpoints de health check.

## Escalabilidade

### Horizontal Scaling

**Producer**:
```bash
docker-compose up -d --scale producer=3
```
MÃºltiplos producers podem gerar eventos simultaneamente.

**Consumer**:
```bash
docker-compose up -d --scale consumer=3
```
Kafka distribui partiÃ§Ãµes entre consumers no mesmo grupo.

### Vertical Scaling

- Aumentar recursos de containers
- Ajustar tamanhos de batch
- Aumentar connection pool

### Kafka Partitioning

```python
# Particionar por user_id para manter ordem
producer.send(
    topic='events',
    key=event['user_id'],  # Garante mesma partiÃ§Ã£o
    value=event
)
```

## Monitoramento

### MÃ©tricas Coletadas

**Producer**:
- Eventos gerados/segundo
- LatÃªncia de envio
- Taxa de erro

**Consumer**:
- Eventos processados/segundo
- Lag do consumer
- Taxa de sucesso

**Database**:
- ConexÃµes ativas
- Query time
- Tamanho da base

### Logging

Todos os componentes usam logging estruturado:

```python
logger.info(
    f"Evento processado: {event_id} | "
    f"Tipo: {event_type} | "
    f"LatÃªncia: {latency}ms"
)
```

## SeguranÃ§a

### Boas PrÃ¡ticas Implementadas

1. **Credenciais**: Via variÃ¡veis de ambiente
2. **Network isolation**: Docker network privada
3. **Least privilege**: UsuÃ¡rios de banco com mÃ­nimos privilÃ©gios
4. **Input validation**: SanitizaÃ§Ã£o de inputs
5. **SQL injection protection**: Prepared statements

### Melhorias Futuras

- [ ] TLS/SSL para Kafka
- [ ] AutenticaÃ§Ã£o JWT no dashboard
- [ ] Encryption at rest para PostgreSQL
- [ ] Rate limiting nas APIs
- [ ] CORS configuration

## Performance

### Benchmarks (Ambiente Local)

| MÃ©trica | Valor |
|---------|-------|
| Throughput Producer | ~2000 eventos/s |
| Throughput Consumer | ~1500 eventos/s |
| LatÃªncia E2E | < 100ms (p95) |
| CPU Usage | ~30% (total) |
| Memory Usage | ~2GB (total) |

### OtimizaÃ§Ãµes Aplicadas

1. Batch processing
2. Connection pooling
3. Ãndices apropriados
4. Prepared statements
5. Async I/O onde possÃ­vel

## Disaster Recovery

### Backup Strategy

**PostgreSQL**:
```bash
# Backup manual
docker-compose exec postgres pg_dump -U admin pipeline_db > backup.sql

# Restore
docker-compose exec -T postgres psql -U admin pipeline_db < backup.sql
```

**Kafka**:
- Retention de 7 dias
- ReplicaÃ§Ã£o (em cluster)

### High Availability

Para produÃ§Ã£o, considerar:
- Kafka cluster (3+ brokers)
- PostgreSQL replicaÃ§Ã£o (master-slave)
- Load balancer para dashboard
- Container orchestration (Kubernetes)

## Troubleshooting

### Problemas Comuns

**1. Consumer Lag**
```bash
# Verificar lag
docker-compose exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group ecommerce-consumer-group \
  --describe
```

SoluÃ§Ã£o: Aumentar nÃºmero de consumers

**2. Database Locks**
```sql
-- Verificar locks
SELECT * FROM pg_locks WHERE NOT granted;
```

SoluÃ§Ã£o: Otimizar queries, reduzir batch size

**3. Memory Issues**
```bash
# Verificar uso de memÃ³ria
docker stats
```

SoluÃ§Ã£o: Ajustar heap size do Kafka/JVM

## DependÃªncias

```
Producer â†’ Kafka
Consumer â†’ Kafka, PostgreSQL
Dashboard â†’ PostgreSQL
Kafka â†’ Zookeeper
```

## ReferÃªncias

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [PostgreSQL Best Practices](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [Python Kafka Client](https://kafka-python.readthedocs.io/)
- [Flask Documentation](https://flask.palletsprojects.com/)
